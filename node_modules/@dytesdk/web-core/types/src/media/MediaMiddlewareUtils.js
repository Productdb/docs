var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
var __metadata = (this && this.__metadata) || function (k, v) {
    if (typeof Reflect === "object" && typeof Reflect.metadata === "function") return Reflect.metadata(k, v);
};
import * as WorkerTimers from 'worker-timers';
import DyteTelemetry from '../utils/opentelemetry';
import { browserSpecs } from '../browser/BrowserCapabilities';
import DyteLogger from '../client/internals/DyteLogger';
export default class MediaMiddlewareUtils {
    #localMediaHandler;
    audioMiddlewares = [];
    videoMiddlewares = [];
    #middlewareWebWorkerInterval = undefined;
    constructor(localMediaHandler) {
        this.#localMediaHandler = localMediaHandler;
    }
    terminateMiddlewareWebWorker() {
        if (this.#middlewareWebWorkerInterval) {
            try {
                WorkerTimers.clearInterval(this.#middlewareWebWorkerInterval);
                this.#middlewareWebWorkerInterval = undefined;
            }
            catch (ex) {
                DyteLogger.debug('WorkerTimers::terminateMiddlewareWebWorker::failed');
            }
        }
    }
    async getTransformedVideoTrack(originalVideoTrack) {
        if (!this.videoMiddlewares?.length) {
            return originalVideoTrack;
        }
        const middlewares = await Promise.all(this.videoMiddlewares?.map((videoMiddleware) => videoMiddleware()));
        const originalVideoStream = new MediaStream();
        originalVideoStream.addTrack(originalVideoTrack);
        const transformedVideoCanvasElement = document.createElement('canvas');
        const transformedVideoCanvasCtx = transformedVideoCanvasElement.getContext('2d');
        const rawVideoFeedElement = document.createElement('video');
        rawVideoFeedElement.srcObject = originalVideoStream;
        rawVideoFeedElement.autoplay = true;
        this.terminateMiddlewareWebWorker();
        const intervalCallback = async () => {
            if (!this.#localMediaHandler.videoEnabled
                || originalVideoTrack.readyState === 'ended') {
                this.terminateMiddlewareWebWorker();
                rawVideoFeedElement.remove();
                transformedVideoCanvasElement.remove();
                return;
            }
            try {
                transformedVideoCanvasCtx.drawImage(rawVideoFeedElement, 0, 0);
                for (let middlewareIndex = 0; middlewareIndex < middlewares.length; middlewareIndex += 1) {
                    await middlewares[middlewareIndex](transformedVideoCanvasElement, transformedVideoCanvasCtx);
                }
            }
            catch (error) {
                DyteLogger.error('getTransformedVideoTrack::middleware_execution_failed', { error });
            }
        };
        try {
            rawVideoFeedElement.play();
        }
        catch (ex) {
        }
        rawVideoFeedElement.addEventListener('play', () => {
            transformedVideoCanvasElement.width = rawVideoFeedElement.width
                || originalVideoTrack.getSettings().width;
            transformedVideoCanvasElement.height = rawVideoFeedElement.width
                || originalVideoTrack.getSettings().height;
            this.#middlewareWebWorkerInterval = WorkerTimers.setInterval(intervalCallback, 50);
        }, false);
        const canvasMediaStream = transformedVideoCanvasElement.captureStream();
        return canvasMediaStream.getVideoTracks()[0];
    }
    async addVideoMiddleware(videoMiddleware) {
        if (browserSpecs.isSafari()) {
            return { success: false, message: 'Video middlewares are not yet supported in Safari.' };
        }
        if (this.videoMiddlewares.includes(videoMiddleware)) {
            return { success: true, message: 'This video middleware has been applied, already. Skipping.' };
        }
        this.videoMiddlewares.push(videoMiddleware);
        if (this.#localMediaHandler.videoEnabled) {
            this.#localMediaHandler.setVideoTrack(await this.getTransformedVideoTrack(this.#localMediaHandler.rawVideoTrack));
            this.#localMediaHandler.emit('VIDEO_TRACK_CHANGE');
            return { success: true, message: 'Successfully applied the video middleware.' };
        }
        return { success: true, message: 'Successfully added the video middleware. It will be applied automatically once webcam is turned on.' };
    }
    async removeVideoMiddleware(videoMiddleware) {
        const index = this.videoMiddlewares.indexOf(videoMiddleware, 0);
        if (index > -1) {
            this.videoMiddlewares.splice(index, 1);
            if (this.#localMediaHandler.videoEnabled) {
                this.#localMediaHandler.setVideoTrack(await this.getTransformedVideoTrack(this.#localMediaHandler.rawVideoTrack));
                this.#localMediaHandler.emit('VIDEO_TRACK_CHANGE');
            }
            return { success: true, message: 'Successfully removed the video middleware.' };
        }
        return { success: true, message: 'No such video middleware was found. Skipping.' };
    }
    async getTransformedAudioTrack(originalAudioTrack) {
        if (!this.audioMiddlewares?.length) {
            return originalAudioTrack;
        }
        const audioContext = new AudioContext();
        const middlewares = await Promise.all(this.audioMiddlewares?.map((audioMiddleware) => audioMiddleware(audioContext)));
        const mediaStreamSource = audioContext
            .createMediaStreamSource(new MediaStream([originalAudioTrack]));
        const transformedStreamHolder = audioContext.createMediaStreamDestination();
        try {
            let lastMediaStreamSource = mediaStreamSource;
            for (let middlewareIndex = 0; middlewareIndex < middlewares.length; middlewareIndex += 1) {
                lastMediaStreamSource.connect(middlewares[middlewareIndex]);
                lastMediaStreamSource = middlewares[middlewareIndex];
            }
            lastMediaStreamSource.connect(transformedStreamHolder);
        }
        catch (error) {
            DyteLogger.error('getTransformedAudioTrack::middleware_execution_failed', { error });
            return originalAudioTrack;
        }
        return transformedStreamHolder.stream.getAudioTracks()[0];
    }
    async addAudioMiddleware(audioMiddleware) {
        if (browserSpecs.isSafari()) {
            return { success: false, message: 'Audio middlewares are not yet supported in Safari.' };
        }
        if (this.audioMiddlewares.includes(audioMiddleware)) {
            return { success: true, message: 'This audio middleware has been applied, already. Skipping.' };
        }
        this.audioMiddlewares.push(audioMiddleware);
        if (this.#localMediaHandler.audioEnabled) {
            this.#localMediaHandler.setAudioTrack(await this.getTransformedAudioTrack(this.#localMediaHandler.rawAudioTrack));
            this.#localMediaHandler.emit('AUDIO_TRACK_CHANGE');
            return { success: true, message: 'Successfully applied the audio middleware.' };
        }
        return { success: true, message: 'Successfully added the audio middleware. It will be applied automatically once mic is turned on.' };
    }
    async removeAudioMiddleware(audioMiddleware) {
        const index = this.audioMiddlewares.indexOf(audioMiddleware, 0);
        if (index > -1) {
            this.audioMiddlewares.splice(index, 1);
            if (this.#localMediaHandler.audioEnabled) {
                this.#localMediaHandler.setAudioTrack(await this.getTransformedAudioTrack(this.#localMediaHandler.rawAudioTrack));
                this.#localMediaHandler.emit('AUDIO_TRACK_CHANGE');
            }
            return { success: true, message: 'Successfully removed the audio middleware.' };
        }
        return { success: true, message: 'No such audio middleware was found. Skipping.' };
    }
}
__decorate([
    DyteTelemetry.trace('MediaMiddlewareUtils.getTransformedVideoTrack'),
    __metadata("design:type", Function),
    __metadata("design:paramtypes", [MediaStreamTrack]),
    __metadata("design:returntype", Promise)
], MediaMiddlewareUtils.prototype, "getTransformedVideoTrack", null);
__decorate([
    DyteTelemetry.trace('MediaMiddlewareUtils.addVideoMiddleware'),
    __metadata("design:type", Function),
    __metadata("design:paramtypes", [Function]),
    __metadata("design:returntype", Promise)
], MediaMiddlewareUtils.prototype, "addVideoMiddleware", null);
__decorate([
    DyteTelemetry.trace('MediaMiddlewareUtils.removeVideoMiddleware'),
    __metadata("design:type", Function),
    __metadata("design:paramtypes", [Function]),
    __metadata("design:returntype", Promise)
], MediaMiddlewareUtils.prototype, "removeVideoMiddleware", null);
__decorate([
    DyteTelemetry.trace('MediaMiddlewareUtils.getTransformedAudioTrack'),
    __metadata("design:type", Function),
    __metadata("design:paramtypes", [MediaStreamTrack]),
    __metadata("design:returntype", Promise)
], MediaMiddlewareUtils.prototype, "getTransformedAudioTrack", null);
__decorate([
    DyteTelemetry.trace('MediaMiddlewareUtils.addAudioMiddleware'),
    __metadata("design:type", Function),
    __metadata("design:paramtypes", [Function]),
    __metadata("design:returntype", Promise)
], MediaMiddlewareUtils.prototype, "addAudioMiddleware", null);
__decorate([
    DyteTelemetry.trace('MediaMiddlewareUtils.removeAudioMiddleware'),
    __metadata("design:type", Function),
    __metadata("design:paramtypes", [Function]),
    __metadata("design:returntype", Promise)
], MediaMiddlewareUtils.prototype, "removeAudioMiddleware", null);
