import { beforeEach, describe, expect, test, vi, } from 'vitest';
import setupMockedWindow from '../../../__mocks__/window';
import WebMediaInterface from '../interface/web/WebMediaInterface';
import { getTransformedAudioTrack } from '../middleware/AudioMiddlewareUtils';
import AudioMediaHandler from './AudioMediaHandler';
setupMockedWindow();
vi.mock('../../utils/opentelemetry');
vi.mock('../interface/web/WebMediaInterface');
vi.mock('../middleware/AudioMiddlewareUtils');
let audioMediaHandler;
let device;
let mediaTrack;
let webMediaInterface;
const middleware = (ctx) => Promise.resolve(new AudioWorkletNode(ctx, ''));
describe('Given AudioMediaHandler is initialized', () => {
    beforeEach(() => {
        webMediaInterface = new WebMediaInterface();
        mediaTrack = new MediaStreamTrack();
        webMediaInterface.getAudioTrack = vi.fn(async () => mediaTrack);
        audioMediaHandler = new AudioMediaHandler(webMediaInterface);
        audioMediaHandler.emit = vi.fn();
        device = new MediaDeviceInfo();
    });
    describe('When setDevice is called', () => {
        test('Then it should throw an error when no device is passed', async () => {
            try {
                await audioMediaHandler.setDevice();
            }
            catch (err) {
                expect(err.message.includes('No device received!')).toBeTruthy();
            }
        });
        test('Then it should throw an error when the received device is not an audio device', async () => {
            try {
                device.kind = 'videoinput';
                await audioMediaHandler.setDevice(device);
            }
            catch (err) {
                expect(err.message.includes('Non audio device received while setting device!')).toBeTruthy();
            }
        });
        beforeEach(async () => {
            await audioMediaHandler.setDevice(device);
        });
        test('Then mediaTrack device should be set', () => {
            expect(audioMediaHandler.mediaTrack).toBeDefined();
        });
        describe('When setMediaTrack throws an error', () => {
            let error;
            beforeEach(async () => {
                audioMediaHandler.disableTrack = vi.fn();
                audioMediaHandler.setMediaTrack = vi.fn(() => { throw new Error('Dummy Error'); });
                try {
                    await audioMediaHandler.setDevice(device);
                }
                catch (err) {
                    error = err;
                }
            });
            test('Then track should be disabled', () => {
                expect(audioMediaHandler.disableTrack).toBeCalled();
            });
            test('Then expect error to be defined', () => {
                expect(error).toBeDefined();
            });
        });
    });
    describe('When enableTrack is called', () => {
        beforeEach(async () => {
            audioMediaHandler.setMediaTrack = vi.fn();
            await audioMediaHandler.enableTrack(true);
        });
        test('Then getAudioTrack must be called', () => {
            expect(webMediaInterface.getAudioTrack).toBeCalled();
        });
        test('Then setMediaTrack should be called with a mediaStreamTrack', () => {
            expect(audioMediaHandler.setMediaTrack).toBeCalledWith(mediaTrack);
        });
    });
    describe('When setTransformedTrack is called', () => {
        test('Then it should not call getTransformedAudioTrack when middlewares are absent', async () => {
            await audioMediaHandler.setTransformedTrack();
            expect(getTransformedAudioTrack).not.toBeCalled();
        });
        describe('When middlewares are present', () => {
            beforeEach(async () => {
                await audioMediaHandler.addMiddleware(middleware);
                await audioMediaHandler.setTransformedTrack();
            });
            test('Then getTransformedAudioTrack should be called', () => {
                expect(getTransformedAudioTrack).toBeCalled();
            });
            test('Then it should emit trackChanged', () => {
                expect(audioMediaHandler.emit).toBeCalledWith('trackChanged');
            });
            test('Then it should set transformedMediaTrack to mediaTrack when anything errors out', async () => {
                getTransformedAudioTrack = vi.fn(() => { throw new Error('Dummy Error'); });
                await audioMediaHandler.addMiddleware(middleware);
                await audioMediaHandler.setTransformedTrack();
                expect(audioMediaHandler.transformedMediaTrack).toBe(audioMediaHandler.mediaTrack);
            });
        });
    });
    describe('When mediaTrack emits events', () => {
        const webMediaInterface2 = new WebMediaInterface();
        const mediaTrack2 = new MediaStreamTrack();
        const audioMediaHandler2 = new AudioMediaHandler(webMediaInterface2, mediaTrack2);
        audioMediaHandler2.disableTrack = vi.fn();
        audioMediaHandler2.enableTrack = vi.fn();
        audioMediaHandler2.setTransformedTrack = vi.fn();
        audioMediaHandler2.emit = vi.fn();
        describe('When mediaTrack emits \'mute\' event', () => {
            test('Then trackMuted event should be emitted', () => {
                mediaTrack2.emit('mute');
                expect(audioMediaHandler2.emit).toBeCalledWith('trackMuted');
            });
        });
        describe('When mediaTrack emits \'ended\' event', () => {
            beforeEach(async () => {
                await mediaTrack2.emit('ended');
            });
            test('Then disableTrack, enableTrack, setTransformedTrack should be called', async () => {
                expect(audioMediaHandler2.disableTrack).toBeCalled();
                expect(audioMediaHandler2.enableTrack).toBeCalled();
                expect(audioMediaHandler2.setTransformedTrack).toBeCalled();
            });
            test('Then trackMuted event should be emitted', async () => {
                expect(audioMediaHandler2.emit).toBeCalledWith('trackChanged');
            });
        });
    });
});
